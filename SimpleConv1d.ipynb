{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleConv1d.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBySv4zhfxt4"
      },
      "source": [
        "# SimpleConv1d\n",
        "## Name: Nguyen Anh Hoang Phuc\n",
        "\n",
        "### One-dimensional convolutional neural network scratch\n",
        "\n",
        "Let's create the class Convolutional Neural Network (CNN) from scratch. We will implement the algorithm using only the minimum library such as NumPy.\n",
        "\n",
        "In this Sprint, we will build a 1D Convolutional layer and try to understand the basics of convolution. The next Sprint completes the CNN commonly used for images by creating a two-dimensional convolutional layer and a pooling layer.\n",
        "\n",
        "Name the class Scratch1dCNNClassifier. Please refer to the ScratchDeepNeuralNetrowkClassifier created in the previous Sprint for the class structure.\n",
        "\n",
        "### What is a one-dimensional convolutional layer?\n",
        "\n",
        "In CNN, a two-dimensional convolutional layer for images is a standard, but here, to make it easier to understand, we first implement a one-dimensional convolutional layer. One-dimensional convolution is practically often used in Series data such as natural language and waveform data.\n",
        "\n",
        "Convolution can be considered for any dimension, and frameworks generally provide up to 3D convolution for 3D data.\n",
        "\n",
        "### Preparing the dataset\n",
        "\n",
        "We will continue to use the MNIST dataset for validation, with the 1D convolution taking a smoothed input as well as a fully connected neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVgxNG2Ehf6z"
      },
      "source": [
        "### Dataset Preparation\n",
        "We will continue to use the MNIST dataset validation; for 1D convolution we will input a smoothed version as well as an all-connected neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y6e0k-yPFu8"
      },
      "source": [
        "# Mini-batch processing class\n",
        "class GetMiniBatch:\n",
        "  \"\"\"\n",
        "  Iterator to get the mini-batch\n",
        "\n",
        "  Parameters\n",
        "  ===========\n",
        "  X: ndarray of the following form, shape (n_samples, n_features)\n",
        "     Training data\n",
        "  y: ndarray of the following form, shape (n_samples, 1)\n",
        "     Correct value\n",
        "  batch_size: int\n",
        "     Batch size\n",
        "  seed: int\n",
        "     Seeding random numbers in NumPy\n",
        "  \"\"\"\n",
        "  def __init__(self, X, y, batch_size = 20, seed=None):\n",
        "    self.batch_size = batch_size\n",
        "    np.random.seed(seed)\n",
        "    shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "    self._X = X[shuffle_index]\n",
        "    self._y = y[shuffle_index]\n",
        "    self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._stop\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    p0 = item*self.batch_size\n",
        "    p1 = item*self.batch_size + self.batch_size\n",
        "    return self._X[p0:p1], self._y[p0:p1]\n",
        "\n",
        "  def __iter__(self):\n",
        "    self._counter = 0\n",
        "    return self\n",
        "  \n",
        "  def __next__(self):\n",
        "    if self._counter >= self._stop:\n",
        "      raise StopIteration()\n",
        "    p0 = self._counter*self.batch_size\n",
        "    p1 = self._counter*self.batch_size + self.batch_size\n",
        "    self._counter += 1\n",
        "    return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGantzo9k62S"
      },
      "source": [
        "All binding layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQgmFUIpjWL0"
      },
      "source": [
        "class FC:\n",
        "  \"\"\"\n",
        "  All coupling layers from number of nodes n_nodes1 to n_nodes2\n",
        "  Parameters\n",
        "  ==========\n",
        "  n_nodes1: int\n",
        "    Number of nodes in the previous layer\n",
        "  n_nodes2: int\n",
        "    Number of nodes in subsequent layers\n",
        "  initializer: Instances of initialization methods\n",
        "  optimizer: Instances of optimizations methods\n",
        "  \"\"\"\n",
        "  def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, activation):\n",
        "    self.n_nodes1 = n_nodes1\n",
        "    self.n_nodes2 = n_nodes2\n",
        "    self.initializer = initializer\n",
        "    self.optimizer = optimizer\n",
        "    self.activation = activation\n",
        "    # Initialize\n",
        "    # Use the initializer method to initialize self.w and self.B\n",
        "    self.W = self.initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "    self.B = self.initializer.B(self.n_nodes2)\n",
        "\n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward\n",
        "    Parameters\n",
        "    ==========\n",
        "    X: ndarray of the following form, shape (batch_size, n_nodes1)\n",
        "      Input\n",
        "    Returns\n",
        "    ==========\n",
        "    A: ndarray of the following form, shape (batch_size, n_nodes2)\n",
        "      Output\n",
        "    \"\"\"\n",
        "    self.X = X\n",
        "    self.A = np.dot(self.X, self.W) + self.B\n",
        "\n",
        "    return self.activation.forward(self.A)\n",
        "\n",
        "  def backward(self, dZ):\n",
        "    \"\"\"\n",
        "    backward\n",
        "    Parameters\n",
        "    ==========\n",
        "    dA: ndarray of the following form, shape (batch_size, n_nodes2)\n",
        "      The gradient flowed in from behind\n",
        "    Returns\n",
        "    ==========\n",
        "    dZ: ndarray of the following form, shape (batch_size, n_nodes1)\n",
        "      forward slope\n",
        "    \"\"\"\n",
        "    dA = self.activation.backward(dZ)\n",
        "    self.dB = np.mean(dA, axis=0)\n",
        "    self.dW = np.dot(self.X.T, dA)/len(self.X)\n",
        "    dZ = np.dot(dA, self.W.T)\n",
        "\n",
        "    # Update\n",
        "    self = self.optimizer.update(self)\n",
        "\n",
        "    return dZ\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnJRHJzvo4U1"
      },
      "source": [
        "class SimpleInitializer:\n",
        "  \"\"\"\n",
        "  Simple initialization with Gaussian distribution\n",
        "  Parameters\n",
        "  ==========\n",
        "  sigma: float\n",
        "    Standard deviation of Gaussian distribution\n",
        "  \"\"\"\n",
        "  def __init__(self, sigma):\n",
        "    self.sigma = sigma\n",
        "\n",
        "  def W(self, n_nodes1, n_nodes2):\n",
        "    \"\"\"\n",
        "    Initializing weights\n",
        "    Parameters\n",
        "    ==========\n",
        "    n_nodes1: int\n",
        "      Number of nodes in the previous layer\n",
        "    n_nodes2: int\n",
        "      Number of nodes in subsequent layers\n",
        "    \n",
        "    Returns\n",
        "    ==========\n",
        "    W: weight\n",
        "    \"\"\"\n",
        "    return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "    \n",
        "  def B(self, n_nodes2):\n",
        "    \"\"\"\n",
        "    Bias initialization\n",
        "    Parameters\n",
        "    ==========\n",
        "    n_nodes2: int\n",
        "      Number of nodes in subsequent layers\n",
        "    \n",
        "    Returns\n",
        "    ==========\n",
        "    B: bias\n",
        "    \"\"\"\n",
        "    return np.zeros(n_nodes2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mv3E7xSqAWx"
      },
      "source": [
        "class HeInitializer():\n",
        "  \"\"\"\n",
        "  Initialization of weights by He\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def W(self, n_nodes1, n_nodes2):\n",
        "    \"\"\"\n",
        "    Initializing weights\n",
        "    Parameters\n",
        "    ==========\n",
        "    n_nodes1: int\n",
        "      Number of nodes in the previous layer\n",
        "    n_nodes2: int\n",
        "      Number of nodes in subsequent layers\n",
        "    \n",
        "    Returns\n",
        "    ==========\n",
        "    W: weight\n",
        "    \"\"\"\n",
        "    return np.random.randn(n_nodes1, n_nodes2)*np.sqrt(2/n_nodes1)\n",
        "\n",
        "  def B(self, n_nodes2):\n",
        "    \"\"\"\n",
        "    Bias initialization\n",
        "    Parameters\n",
        "    ==========\n",
        "    n_nodes2: int\n",
        "      Number of nodes in subsequent layers\n",
        "    \n",
        "    Returns\n",
        "    ==========\n",
        "    B: bias\n",
        "    \"\"\"\n",
        "    return np.zeros(n_nodes2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHx3Ha_CqjGT"
      },
      "source": [
        "class SGD:\n",
        "  \"\"\"\n",
        "  stochastic gradient descent method\n",
        "  Parameters\n",
        "  ==========\n",
        "  lr: learning rate\n",
        "  \"\"\"\n",
        "  def __init__(self, lr):\n",
        "    self.lr = lr \n",
        "  \n",
        "  def update(self, layer):\n",
        "    \"\"\"\n",
        "    Updating the weights and biases of a layer\n",
        "    Parameters\n",
        "    ==========\n",
        "    layers: As instance of the layer before the update\n",
        "    \"\"\"\n",
        "    layer.W -= self.lr*layer.dW\n",
        "    layer.B -= self.lr*layer.dB\n",
        "\n",
        "    return layer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f966J3WArQY0"
      },
      "source": [
        "class AdaGrad:\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ==========\n",
        "  lr: learning rate\n",
        "  \"\"\"\n",
        "  def __init__(self, lr):\n",
        "    self.lr = lr\n",
        "    self.hW = 0\n",
        "    self.hB = 0\n",
        "  \n",
        "  def update(self, layer):\n",
        "    \"\"\"\n",
        "    Updating the weights and biases of a layer\n",
        "    Parameters\n",
        "    ==========\n",
        "    layer: An instance of the layer before the update\n",
        "    \"\"\"\n",
        "    self.hW += layer.dW*layer.dW\n",
        "    self.hB = layer.dB*layer.dB\n",
        "\n",
        "    layer.W -= self.lr*layer.dW/(np.sqrt(self.hW) +1e-7)\n",
        "    layer.B -= self.lr*layer.dB/(np.sqrt(self.hB) +1e-7)\n",
        "\n",
        "    return layer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TZ_9YOEsLFP"
      },
      "source": [
        "## Activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlzdmNLHsH7y"
      },
      "source": [
        "class ReLU():\n",
        "  \"\"\"\n",
        "  Activation function: ReLU function\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def forward(self, A):\n",
        "    self.A = A\n",
        "    return np.maximum(self.A,0)\n",
        "  \n",
        "  def backward(self, dZ):\n",
        "    return np.where(self.A>0,dZ,0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqUCOEs5spmj"
      },
      "source": [
        "class Softmax():\n",
        "  \"\"\"\n",
        "  Activation function: Softmax function\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def forward(self, A):\n",
        "    return np.exp(A-np.max(A))/np.sum(np.exp(A-np.max(A)), axis=1, keepdims=True)\n",
        "  \n",
        "  def backward(self, dZ):\n",
        "    return dZ"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahOQRqZatMVI"
      },
      "source": [
        "## [Problem 1] Creating a one-dimensional convolutional layer class that limits the number of channels to one\n",
        "\n",
        "Create 1-dimensional convolutional layer class SimpleConv1d with the number of channels limited to 1. The basic structure will be the same as the FC class of the fully connected layer created in Sprint above. Recreate the class related to weight initialization if necessary. The point of using the initial value of Xavier is the same as the fully connected layer.\n",
        "\n",
        "Here Padding is not considered, and stride is also fixed to 1. Also, don't worry about processing multiple data at the same time, only support batch size 1. Extension of this part is an advanced task.\n",
        "\n",
        "The formula for forward propagation is as follows\n",
        "\n",
        "$a_{i}=\\sum_{s=0}^{F-1} x_{(i+s)} w_{s}+b$\n",
        "\n",
        "$a_i$: The i-th value in the output array\n",
        "\n",
        "$F$: Filter size\n",
        "\n",
        "$x_{(i+s)}$: (i+s)th value in the input array\n",
        "\n",
        "$w_s$: the sth value in the array of weights\n",
        "\n",
        "$b$: Bias term\n",
        "\n",
        "All are scalars.\n",
        "\n",
        "Next is the update formula. It is similar to the fully connected layer in that it is replaced with AdaGrad etc.\n",
        "\n",
        "$\\begin{aligned} w_{s}^{\\prime} &=w_{s}-\\alpha \\frac{\\partial L}{\\partial w_{s}} \\\\ b^{\\prime} &=b-\\alpha \\frac{\\partial L}{\\partial b} \\end{aligned}$\n",
        "\n",
        "$\\alpha$: learning rate\n",
        "\n",
        "$\\frac{\\partial L}{\\partial w_s}$: Loss $L$ slope for $w_s$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial b}$: slope of loss $L$ with respect to $b$\n",
        "\n",
        "Here is the backpropagation formula for the gradients $\\frac{\\partial L}{\\partial w_s}$ and $\\frac{\\partial L}{\\partial b}$.\n",
        "\n",
        "$\\frac{\\partial L}{\\partial w_{s}}=\\sum_{i=0}^{N_{o u t}-1} \\frac{\\partial L}{\\partial a_{i}} x_{(i+s)}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial b}=\\sum_{i=0}^{N_{o u t}-1} \\frac{\\partial L}{\\partial a_{i}}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial a_i}$: i-th value in the gradient array\n",
        "\n",
        "$N_{out}$: Output size\n",
        "\n",
        "The formula for the error to be passed to the previous layer is as follows\n",
        "\n",
        "$\\frac{\\partial L}{\\partial x_{j}}=\\sum_{s=0}^{F-1} \\frac{\\partial L}{\\partial a_{(j-s)}} w_{s}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial x_j}$: jth value of the error array to be passed to the previous layer\n",
        "\n",
        "However, when $js<0$ or $js>N_{out}-1$, $\\frac{\\partial L}{\\partial a_{(js)}} =0$.\n",
        "\n",
        "The major difference from the fully connected layer is that the weights are shared for multiple features. In this case, the gradient is calculated by adding all the shared errors. For branching on the calculation graph, the error should be added at the time of backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhx3zs-VtEf2"
      },
      "source": [
        "# Import\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Evaluation index\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoIXXNtptkCP"
      },
      "source": [
        "### Convoluation layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzrnEKTQthyo"
      },
      "source": [
        "# 1D convoluational layer class\n",
        "class SimpleConv1d():\n",
        "  \"\"\"\n",
        "  1D convolutional layer\n",
        "  Parameters\n",
        "  ==========\n",
        "  n_nodes1: int\n",
        "    Number of nodes in the previous layer\n",
        "  n_nodes2: int\n",
        "    Number of nodes in subsequent layers\n",
        "  initializer: Instances of initialization methods\n",
        "  optimizer: Instances of optimizations methods\n",
        "  \"\"\"\n",
        "  def __init__(self, out_channel, in_channel, filter_size, padding_size=0, stride_size=1, initializer=None, optimizer=None, activation=None):\n",
        "    self.initializer = initializer\n",
        "    self.optimizer = optimizer\n",
        "    self.activation = activation\n",
        "\n",
        "    # Initialize\n",
        "    # Use the initializer method to initialize self.W and self.B\n",
        "    self.W = self.initializer.W(out_channel, in_channel, filter_size)\n",
        "    self.B = self.initializer.B(out_channel)\n",
        "\n",
        "  def output_shape(self,n_feature,filter_size,padding=0,stride=1):\n",
        "    return int((n_feature + 2*padding - filter_size)/stride + 1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward\n",
        "    Parameters\n",
        "    ==========\n",
        "    X: ndarray of the following form, shape (batch_size, n_nodes1)\n",
        "      Input\n",
        "    Returns\n",
        "    ==========\n",
        "    A: ndarray of the following form, shape (batch_size, n_nodes2)\n",
        "      Output\n",
        "    \"\"\"\n",
        "    self.X = X\n",
        "    # Size\n",
        "    N, INC, Feature = X.shape\n",
        "    OCH, INC, FS = self.W.shape\n",
        "    OUT = self.output_shape(Feature,FS,0,1)\n",
        "\n",
        "    self.size = N,INC,OCH,FS,OUT\n",
        "\n",
        "    A = np.zeros([N,OCH,OUT])\n",
        "\n",
        "    for n in range(N):\n",
        "      for och in range(OCH):\n",
        "        for ich in range(INC):\n",
        "          for m in range(OUT):\n",
        "            A[n,och,m] += np.sum(X[n,ich,m:m+FS]*self.W[och,ich,:])\n",
        "    \n",
        "    A += self.B[:,None]\n",
        "\n",
        "    return self.activation.forward(A)\n",
        "\n",
        "  def backward(self, dZ):\n",
        "    \"\"\"\n",
        "    backward\n",
        "    Parameters\n",
        "    ==========\n",
        "    dA: ndarray of the following form, shape (batch_size, n_nodes2)\n",
        "      The gradient flowed in from behind\n",
        "    Returns\n",
        "    ==========\n",
        "    dZ: ndarray of the following form, shape (batch_size, n_nodes1)\n",
        "      forward slope\n",
        "    \"\"\"\n",
        "    dA = self.activation.backward(dZ)\n",
        "\n",
        "    # Bias\n",
        "    self.dB = np.mean(np.sum(dA,axis=2), axis=0)\n",
        "\n",
        "    # Weight, flow slope\n",
        "    self.dW = np.zeros(self.W.shape)\n",
        "    dZ = np.zeros(self.X.shape)\n",
        "\n",
        "    N,INC,OCH,FS,OUT = self.size\n",
        "\n",
        "    for n in range(N):\n",
        "      for och in range(OCH):\n",
        "        for ich in range(INC):\n",
        "          for fs in range(FS):\n",
        "            for m in range(OUT):\n",
        "              self.dW[och,ich,fs] += self.X[n,ich,fs+m]*dA[n,och,m]\n",
        "              dZ[n,ich,fs+m] += self.W[och,ich,fs]*dA[n,och,m]\n",
        "    \n",
        "    # Update\n",
        "    self = self.optimizer.update(self)\n",
        "\n",
        "    return dZ\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8RfhlUc2qnX"
      },
      "source": [
        "class SimpleInitializerConv1d:\n",
        "  \"\"\"\n",
        "  Simple initialization with Gaussian distribution\n",
        "  Parameters\n",
        "  ==========\n",
        "  sigma: float\n",
        "    Standard deviation of Gaussian distribution\n",
        "  \"\"\"\n",
        "  def __init__(self, sigma=0.01):\n",
        "    self.sigma = sigma\n",
        "\n",
        "  def W(self, out_channel, in_channel, filter_size):\n",
        "    \"\"\"\n",
        "    Initializing weights\n",
        "    Parameters\n",
        "    ==========\n",
        "    in_channel: int\n",
        "      Number of nodes in the previous layer\n",
        "    out_channel: int\n",
        "      Number of nodes in subsequent layers\n",
        "    \n",
        "    Returns\n",
        "    ==========\n",
        "    W: weight\n",
        "    \"\"\"\n",
        "    return self.sigma * np.random.randn(out_channel, in_channel, filter_size)\n",
        "    \n",
        "  def B(self, out_channel):\n",
        "    \"\"\"\n",
        "    Bias initialization\n",
        "    Parameters\n",
        "    ==========\n",
        "    out_channel: int\n",
        "      Number of nodes in subsequent layers\n",
        "    \n",
        "    Returns\n",
        "    ==========\n",
        "    B: bias\n",
        "    \"\"\"\n",
        "    return np.zeros(out_channel)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g3eW4s23xOj"
      },
      "source": [
        "# Scratch CNN\n",
        "class Scratch1dCNNClacssifier():\n",
        "  \"\"\"\n",
        "  N-Layer Convolutional Neural Network Classifier\n",
        "\n",
        "  Parameters\n",
        "  ==========\n",
        "  self.n_epoch: epoch number\n",
        "  self.n_batch: Number of batches\n",
        "  self.verbose: Visualizing the learning process\n",
        "  Attributes\n",
        "  ==========\n",
        "  \"\"\"\n",
        "  def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose=False):\n",
        "    # Parameters\n",
        "    self.n_epoch = n_epoch\n",
        "    self.n_batch = n_batch \n",
        "    self.verbose = verbose\n",
        "    self.log_loss = np.zeros(self.n_epoch)\n",
        "    self.log_acc = np.zeros(self.n_epoch)\n",
        "    self.NN = NN\n",
        "    self.CNN = CNN\n",
        "\n",
        "  def loss_function(self,y,yt):\n",
        "    delta = 1e-7\n",
        "    return -np.mean(yt*np.log(y+delta))\n",
        "\n",
        "  def accuracy(self, Z, Y):\n",
        "    return accuracy_score(Y, Z)\n",
        "\n",
        "  def predict(self, X):\n",
        "      \"\"\"\n",
        "      Estimate using a neural network classifier\n",
        "\n",
        "      Parameters\n",
        "      ==========\n",
        "      X: ndarray of the following form, shape (n_samples, n_features)\n",
        "        Sample\n",
        "      \n",
        "      Returns\n",
        "      ==========\n",
        "         ndarray of the following form, shape (n_samples, 1)\n",
        "         Estimation results\n",
        "      \"\"\"\n",
        "      pred_data = X[:,np.newaxis,:]\n",
        "\n",
        "      # Conv\n",
        "      for layer in range(len(self.CNN)):\n",
        "        pred_data = self.CNN[layer].forward(pred_data)\n",
        "      \n",
        "      pred_data = pred_data.reshape(len(X), -1)\n",
        "\n",
        "      for layer in range(len(self.NN)):\n",
        "        pred_data = self.NN[layer].forward(pred_data)\n",
        "\n",
        "      return np.argmax(pred_data, axis=1)\n",
        "\n",
        "  def fit(self, X, y, X_val=False, y_val=False):\n",
        "    \"\"\"\n",
        "    Train a neural network classifier.\n",
        "\n",
        "    Parameters\n",
        "    ==========\n",
        "    X: ndarray of the following form, shape (n_samples, n_features)\n",
        "      Features of training data\n",
        "    y: ndarray of the following form, shape (n_samples, )\n",
        "      Correct answer value of training data\n",
        "    X_val: ndarray of the following form, shape (n_samples, n_features)\n",
        "      Features of validation data\n",
        "    y_val: ndarray of the following form, shape (n_samples, )\n",
        "      Correct value of validation data\n",
        "    \"\"\"\n",
        "    for epoch in range(self.n_epoch):\n",
        "      # Mini-batch processing \n",
        "      get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
        "\n",
        "      self.loss = 0\n",
        "      for mini_X_train, mini_y_train in get_mini_batch:\n",
        "\n",
        "        # Forward propagation\n",
        "        forward_data = mini_X_train.reshape(self.n_batch,1,-1)\n",
        "\n",
        "        # Conv\n",
        "        for layer in range(len(self.CNN)):\n",
        "          forward_data = self.CNN[layer].forward(forward_data)\n",
        "\n",
        "        record_shape = forward_data.shape\n",
        "        forward_data = forward_data.reshape(self.n_batch, -1)\n",
        "\n",
        "        for layer in range(len(self.NN)):\n",
        "          forward_data = self.NN[layer].forward(forward_data)\n",
        "\n",
        "        # Predicted value\n",
        "        Z = forward_data\n",
        "\n",
        "        # Back propagation\n",
        "        backward_data = (Z - mini_y_train)/self.n_batch\n",
        "        for layer in range(len(self.NN)-1,-1,-1):\n",
        "          backward_data = self.NN[layer].backward(backward_data)\n",
        "        \n",
        "        backward_data = backward_data.reshape(record_shape)\n",
        "\n",
        "        for layer in range(len(self.CNN)-1,-1,-1):\n",
        "          backward_data = self.CNN[layer].backward(backward_data)\n",
        "        \n",
        "        # Loss function\n",
        "        self.loss += self.loss_function(Z, mini_y_train)\n",
        "\n",
        "      self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
        "      self.log_acc[epoch] = self.accuracy(self.predict(X), np.argmax(y, axis=1))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUaHjfEIHZrA"
      },
      "source": [
        "## [Problem 2] Output size calculation after one-dimensional convolution\n",
        "\n",
        "When the convolution is performed, the number of features will change. How it changes can be calculated from the following formula. It also includes padding and stride. Create a function to do this calculation.\n",
        "\n",
        "$N_{o u t}=\\frac{N_{i n}+2 P-F}{S}+1$\n",
        "\n",
        "$N_{out}$: Output size (number of features)\n",
        "\n",
        "$N_{in}$: Input size (number of features)\n",
        "\n",
        "$P$: Number of paddings in one direction\n",
        "\n",
        "$F$: Filter size\n",
        "\n",
        "$S$: Stride size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KNiK4wa9HMo"
      },
      "source": [
        "def output_shape(X_features, filter_size, padding_size=0, stride_size=1):\n",
        "  return int((X_features + 2*padding_size - filter_size)/stride_size + 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIaYhFouIGwx",
        "outputId": "3e493cbb-4a0f-4db4-970c-15d2521f4abf"
      },
      "source": [
        "output_shape(4,3,0,1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdy089wUKVVB"
      },
      "source": [
        "## [Problem 3] Experiment of one-dimensional convolutional layer with small array\n",
        "\n",
        "Check if forward propagation and back propagation are performed correctly with the small sequence shown below.\n",
        "\n",
        "Input x, weight w, and bias b are"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq7u1fPSIQfI"
      },
      "source": [
        "# Input\n",
        "x = np.array([1,2,3,4])\n",
        "w = np.array([3, 5, 7])\n",
        "b = np.array([1])\n",
        "\n",
        "# Error\n",
        "delta_a = np.array([10,20])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQoCPhzNSLz2",
        "outputId": "357db18b-7f49-4027-d242-6437e07747ee"
      },
      "source": [
        "# Forward\n",
        "a = np.zeros(output_shape(4,3,0,1))\n",
        "for i in range(len(a)):\n",
        "  x_tmp = x[i:i+len(w)]\n",
        "  a[i] = np.sum(x_tmp*w)+b\n",
        "print(a)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[35. 50.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksmFkP5K6MKb",
        "outputId": "cb1e1d1d-9d12-4f45-e8f1-a069ab801e27"
      },
      "source": [
        "# Backward bias\n",
        "delta_b = np.sum(delta_a)\n",
        "print(delta_b)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgCtIej-6Sff",
        "outputId": "e494f29d-42a1-4177-975e-48b453e76f86"
      },
      "source": [
        "# Backward filter\n",
        "delta_w = np.zeros(len(w))\n",
        "for i in range(len(w)):\n",
        "  x_tmp = x[i:i+len(delta_a)]\n",
        "  delta_w[i] = np.sum(x_tmp*delta_a)\n",
        "print(delta_w)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 50.  80. 110.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDE5cNoC7AV3",
        "outputId": "09f25b91-ef96-4012-a44c-032bcde9a157"
      },
      "source": [
        "# Backward Error to convey to next layer\n",
        "delta_x = np.zeros(len(x))\n",
        "for i in range(len(x)):\n",
        "  zero = np.zeros(len(delta_a)-1)\n",
        "  w_padded = np.concatenate([zero,w,zero],axis=0)\n",
        "  w_tmp = w_padded[i:i+len(delta_a)]\n",
        "  # print(w_tmp)\n",
        "  delta_x[i] = np.sum(w_tmp*delta_a[::-1])\n",
        "print(delta_x)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 30. 110. 170. 140.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyAwjFws-kmE"
      },
      "source": [
        "## Implementation tips\n",
        "When implementing convolution, you can first stack for statements. However, in order to make the calculation as efficient as possible, we will consider a method to calculate the following formulas at once.\n",
        "\n",
        "$a_{i}=\\sum_{s=0}^{F-1} x_{(i+s)} w_{s}+b$\n",
        "\n",
        "Since the bias term is a simple addition, we will look at the weight part.\n",
        "\n",
        "$\\sum_{s=0}^{F-1} x_{(i+s)} w_{s}$\n",
        "\n",
        "This is the dot product of an array of w and an array from which a portion of x is taken. Considering the specific situation, we can calculate it with the following code. In this example, to make the flow easier to understand, the Adamant product is calculated between each element, and then the sum is calculated. This is consequently similar to the dot product.\n",
        "\n",
        "ndarray is a method that utilizes the fact that you can specify the index using an array.\n",
        "\n",
        "If you use a two-dimensional array, you can extract a two-dimensional array from a one-dimensional array.\n",
        "\n",
        "By combining this with broadcasting etc., it is possible to calculate all at once.\n",
        "\n",
        "There is no right answer to the calculation method of convolution, so please make it more efficient in your own way.\n",
        "\n",
        "《Reference》\n",
        "\n",
        "The Integer array indexing part of the following page describes this method.\n",
        "\n",
        "Indexing — NumPy v1.17 Manual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUGGW3k9-btq",
        "outputId": "3420bac1-9809-43ca-cb13-f05183f9a270"
      },
      "source": [
        "x = np.array([1, 2, 3, 4])\n",
        "w = np.array([3, 5, 7])\n",
        "a = np.empty((2, 3))\n",
        "indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
        "indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
        "a[0] = x[indexes0]*w # x [indexes0] is ([1, 2, 3])\n",
        "print(a[0])\n",
        "a[1] = x[indexes1]*w # x[indexes1] is ([2, 3, 4])\n",
        "print(a[1])\n",
        "a = a.sum(axis=1)\n",
        "print(a)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3. 10. 21.]\n",
            "[ 6. 15. 28.]\n",
            "[34. 49.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFrj3YSzA6Zz"
      },
      "source": [
        "## [Problem 4] Creating a one-dimensional convolutional layer class that does not limit the number of channels\n",
        "\n",
        "Create 1-dimensional convolutional layer class Conv1d that does not limit the number of channels to 1.\n",
        "\n",
        "For example, if you have the following x, w, b,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xHyIk4WA10x",
        "outputId": "ea1629a3-6425-41c2-879d-6dc5944b2bf0"
      },
      "source": [
        "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) #shape (2, 4), (number of input channels, number of features).\n",
        "w = np.array([[[1, 1, 2],\n",
        "               [2, 1, 1]],\n",
        "              [[2, 1, 1],\n",
        "               [1, 1, 1]],\n",
        "              [[1, 1, 1],\n",
        "               [1, 1, 1]],]) # Set to 1 for simplification of the example. (Number of output channels, number of input channels, filter size).\n",
        "b = np.array([1, 2, 3]) # (Number of output channels)\n",
        "print(\"x.shape\",x.shape)\n",
        "print(\"w.shape\",w.shape)\n",
        "print(\"b.shape\",b.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape (2, 4)\n",
            "w.shape (3, 2, 3)\n",
            "b.shape (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DHsAQ6-BLnV",
        "outputId": "0b1c6907-e749-4f69-d098-3807f76c7fc3"
      },
      "source": [
        "# Forward\n",
        "a = np.zeros([3,output_shape(4,3,0,1)])\n",
        "\n",
        "for och in range(w.shape[0]):\n",
        "  for ch in range(w.shape[1]):\n",
        "    for m in range(a.shape[1]):\n",
        "      a[och,m] += np.sum(x[ch,m:m+w.shape[2]]*w[och,ch,:])\n",
        "a += b[:,None]\n",
        "print(a)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[21. 29.]\n",
            " [18. 25.]\n",
            " [18. 24.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q63Xdq0nBjdM",
        "outputId": "c72cc2f6-4900-4856-e35d-a0a289ee6e09"
      },
      "source": [
        "# Backward\n",
        "delta_a = np.array([[9,11],\n",
        "                    [32,35],\n",
        "                    [52,56]])\n",
        "print('delta_a:\\n',delta_a)\n",
        "print('delta_a.shape:\\n',delta_a.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_a:\n",
            " [[ 9 11]\n",
            " [32 35]\n",
            " [52 56]]\n",
            "delta_a.shape:\n",
            " (3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsfEuNstD0Ue",
        "outputId": "536f7691-2f36-45ae-c54f-30775396094b"
      },
      "source": [
        "# Backward bias\n",
        "delta_b = np.sum(delta_a,axis=1)\n",
        "print(\"delta_b:\\n\",delta_b)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_b:\n",
            " [ 20  67 108]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-XQwmMKEBWn",
        "outputId": "d98839e5-3f52-4767-8341-e7d449ee84e2"
      },
      "source": [
        "# Backward filter\n",
        "delta_w = np.zeros([3,2,3])\n",
        "\n",
        "for och in range(w.shape[0]):\n",
        "  for ich in range(w.shape[1]):\n",
        "    for fs in range(w.shape[2]):\n",
        "      for m in range(2):\n",
        "        #print(x[ich,fs+m])\n",
        "        #print(delta_a[och,m])\n",
        "        #print(x[ich,fs+m]*delta_a[och,m])\n",
        "        delta_w[och,ich,fs] += (x[ich,fs+m]*delta_a[och,m])\n",
        "print('delta_w:\\n',delta_w)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_w:\n",
            " [[[ 31.  51.  71.]\n",
            "  [ 51.  71.  91.]]\n",
            "\n",
            " [[102. 169. 236.]\n",
            "  [169. 236. 303.]]\n",
            "\n",
            " [[164. 272. 380.]\n",
            "  [272. 380. 488.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10S0BoT5EwDx",
        "outputId": "ec334ba1-b5e6-406f-f6a3-7cdcd8ab314f"
      },
      "source": [
        "# Backward Error to convey to next layer\n",
        "delta_x = np.zeros([2,4])\n",
        "\n",
        "for och in range(w.shape[0]):\n",
        "  for ich in range(w.shape[1]):\n",
        "    for fs in range(w.shape[2]):\n",
        "      for m in range(2):\n",
        "        #print(w[och,ich,fs])\n",
        "        #print(delta_a[och,m])\n",
        "        #print(w[och,ich,fs]*delta_a[och,m])\n",
        "        delta_x[ich,fs+m] += w[och,ich,fs]*delta_a[och,m]\n",
        "print('delta_x:\\n',delta_x)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_x:\n",
            " [[125. 230. 204. 113.]\n",
            " [102. 206. 195. 102.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vmAlbtoFhLj"
      },
      "source": [
        "This is an example with 2 input channels and 3 output channels. After writing the calculation graph, consider backpropagation by hand. Since only sums and products appear in the calculation graph, there is no need to consider the derivative anew.\n",
        "\n",
        "<< Supplement >>\n",
        "\n",
        "When adding the number of channels, there is the question of how to arrange the arrays. The most common order is (Batch size, number of channels, number of features)or (Batch size, number of features, number of channels), but the order is different depending on the library. (Some can be switched and used)\n",
        "\n",
        "For this scratch, please choose which one is more efficient for your own implementation. In the above example we have not considered the batch size, it is (Number of channels, number of features).\n",
        "\n",
        "## [Problem 5] (Advanced task) Implementing padding\n",
        "\n",
        "Add padding functionality to the convolutional layer. In the case of a one-dimensional array, make sure that n features can be increased before and after.\n",
        "\n",
        "The simplest padding is zero padding, which is all zeros, which is common on CNNs. Another method is to repeat the end value.\n",
        "\n",
        "Some frameworks can be specified to keep the size of the original input. It is convenient to have this function as well. There is a padding function in NumPy.\n",
        "\n",
        "numpy.pad — NumPy v1.17 Manual\n",
        "\n",
        "## [Problem 6] (Advanced task) Response to mini batch\n",
        "\n",
        "So far, we have assumed that a batch size of 1 is sufficient for the task. However, in reality, mini-batch learning is performed as in the fully connected layer. Change the Conv1d class so that multiple data can be calculated at the same time.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6JzyWlLFV4-",
        "outputId": "2072b4b9-cecd-44c4-f446-59141d360521"
      },
      "source": [
        "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]*2).reshape(2,2,4)\n",
        "w = np.array([[[1, 1, 2],\n",
        "               [2, 1, 1]],\n",
        "              [[2, 1, 1],\n",
        "               [1, 1, 1]],\n",
        "              [[1, 1, 1],\n",
        "               [1, 1, 1]],]) \n",
        "b = np.array([1, 2, 3]) # (Number of output channels)\n",
        "print(\"x.shape\",x.shape)\n",
        "print(\"w.shape\",w.shape)\n",
        "print(\"b.shape\",b.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape (2, 2, 4)\n",
            "w.shape (3, 2, 3)\n",
            "b.shape (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_VExU3FF9gE",
        "outputId": "c07e67fd-f5f1-42bd-ad7e-d1baab8470d1"
      },
      "source": [
        "# Backward\n",
        "delta_a = np.array([[9,11],\n",
        "                    [32,35],\n",
        "                    [52,56]]*2).reshape(2,3,2)\n",
        "print('delta_a:\\n',delta_a)\n",
        "print('delta_a.shape:\\n',delta_a.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_a:\n",
            " [[[ 9 11]\n",
            "  [32 35]\n",
            "  [52 56]]\n",
            "\n",
            " [[ 9 11]\n",
            "  [32 35]\n",
            "  [52 56]]]\n",
            "delta_a.shape:\n",
            " (2, 3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkZ006RwGQBu"
      },
      "source": [
        "# Size\n",
        "N,INC,Feature = x.shape\n",
        "OCH,INC,FS = w.shape\n",
        "A = output_shape(Feature,FS,0,1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kDVmoeDGcky",
        "outputId": "54fd62c4-703a-4679-c530-8eb12e9f53a1"
      },
      "source": [
        "# Forward\n",
        "a = np.zeros([N,OCH,A])\n",
        "\n",
        "for n in range(N):\n",
        "  for och in range(OCH):\n",
        "    for ich in range(INC):\n",
        "      for m in range(A):\n",
        "        a[n,och,m] += np.sum(x[n,ich,m:m+FS]*w[och,ich,:])\n",
        "a += b[:,None]\n",
        "print(a.shape)\n",
        "print(a)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 2)\n",
            "[[[21. 29.]\n",
            "  [18. 25.]\n",
            "  [18. 24.]]\n",
            "\n",
            " [[21. 29.]\n",
            "  [18. 25.]\n",
            "  [18. 24.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMPiegenG3ui",
        "outputId": "3e2c1da1-184c-47e1-ae10-a747d3d25260"
      },
      "source": [
        "# Backward bias\n",
        "delta_b = np.mean(np.sum(delta_a,axis=2),axis=0)\n",
        "print('delta_b\\n',delta_b)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_b\n",
            " [ 20.  67. 108.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5inl5XDlHR2L",
        "outputId": "d028e4f0-5aa0-4952-a4ca-48e18d2dcb92"
      },
      "source": [
        "# Backward filter\n",
        "delta_w = np.zeros([3,2,3])\n",
        "\n",
        "for n in range(N):\n",
        "  for och in range(OCH):\n",
        "    for ich in range(INC):\n",
        "      for fs in range(FS):\n",
        "        for m in range(A):\n",
        "          delta_w[och,ich,fs] += x[n,ich,fs+m]*delta_a[n,och,m]\n",
        "print('delta_w:\\n',delta_w)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_w:\n",
            " [[[ 62. 102. 142.]\n",
            "  [102. 142. 182.]]\n",
            "\n",
            " [[204. 338. 472.]\n",
            "  [338. 472. 606.]]\n",
            "\n",
            " [[328. 544. 760.]\n",
            "  [544. 760. 976.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXZVNwAuJ0_p",
        "outputId": "01aba231-a50c-4d83-dbae-296a5d442677"
      },
      "source": [
        "# Backward Error to convey to next layer\n",
        "delta_x = np.zeros(x.shape)\n",
        "\n",
        "for n in range(N):\n",
        "  for och in range(OCH):\n",
        "    for ich in range(INC):\n",
        "      for fs in range(FS):\n",
        "        for m in range(A):\n",
        "          delta_x[n,ich,fs+m] += w[och,ich,fs]*delta_a[n,och,m]\n",
        "print('delta_x:\\n',delta_x)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_x:\n",
            " [[[125. 230. 204. 113.]\n",
            "  [102. 206. 195. 102.]]\n",
            "\n",
            " [[125. 230. 204. 113.]\n",
            "  [102. 206. 195. 102.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CQaI3Y9KzBA"
      },
      "source": [
        "## [Problem 7] (Advance assignment) Arbitrary number of strides\n",
        "\n",
        "We have implemented only one stride, but please make sure to support any number of strides.\n",
        "\n",
        "## [Problem 8] Learning and estimation\n",
        "\n",
        "Replace Conv1d in part of the fully connected layer of the neural network you have used so far, learn and estimate MNIST, and calculate Accuracy.\n",
        "\n",
        "Use the fully connected layer as is for the output layer. However, when there are multiple channels, input to the fully coupled layer cannot be performed. At that stage, the channel should be set to 1, or smoothing should be performed.​ ​​ ​\n",
        "\n",
        "The accuracy does not matter because one-dimensional convolution of the image is not performed in practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgbSQhc0KgIC"
      },
      "source": [
        "# Download the MNIST dataset\n",
        "from keras.datasets import mnist\n",
        "(X,y), (X_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boiWghsTLPkU",
        "outputId": "c45a3115-7f25-40b4-904a-8288ed057e45"
      },
      "source": [
        "# Check the data\n",
        "print(X.shape) #(60000, 28, 28)\n",
        "print(X_test.shape) #(10000, 28, 28)\n",
        "print(X[0].dtype) #uint8"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_rAZ_fNLefX",
        "outputId": "52731f03-4a44-4c4d-ba03-086ecd29dc13"
      },
      "source": [
        "# Smoothing\n",
        "X_flat = X.reshape(-1,784)\n",
        "X_test_flat = X_test.reshape(-1,784)\n",
        "print(X_flat.shape)\n",
        "print(X_test_flat.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_GvyhM_Lv8d",
        "outputId": "a5201b1d-4e6a-43ce-8172-59a26b25a9dd"
      },
      "source": [
        "# Type conversion, normalization\n",
        "X_flat = X_flat.astype(np.float)\n",
        "X_test_flat = X_test_flat.astype(np.float)\n",
        "X_flat /= 255\n",
        "X_test_flat /= 255\n",
        "print(X_flat.max()) # 1.0\n",
        "print(X_flat.min()) # 0.0"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxlJeam9MhNr",
        "outputId": "11c6e510-ee20-4d8e-97b5-b10e50ccf85a"
      },
      "source": [
        "# One-hot encoding of correct label value\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_one_hot = enc.fit_transform(y[:,np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:,np.newaxis])\n",
        "print(y.shape) #(60000,)\n",
        "print(y_one_hot.shape) #(60000, 10)\n",
        "print(y_one_hot.dtype) #float64"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kua8D5-hNj6X",
        "outputId": "569c63d0-7ad7-4cd3-b992-15c34032d56f"
      },
      "source": [
        "# Split into training data and validation data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_flat, y_one_hot, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_train.shape)\n",
        "print(y_valid.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n",
            "(48000, 10)\n",
            "(12000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6fJ8vdlOUMk"
      },
      "source": [
        "### Learning and estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNtfebNSOM9b"
      },
      "source": [
        "NN = {0:FC(15640, 400, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "      1:FC(400, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "      2:FC(200, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),\n",
        "      }"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1bZJq4jPVLU"
      },
      "source": [
        "CNN = {0:SimpleConv1d(out_channel=20, in_channel=1, filter_size=3,\n",
        "                      padding_size=0, stride_size=1,\n",
        "                      initializer=SimpleInitializerConv1d(0.01),\n",
        "                      optimizer=SGD(0.01),\n",
        "                      activation=ReLU()),\n",
        "      }"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQQQapTcPa4y"
      },
      "source": [
        "cnn1 = Scratch1dCNNClacssifier(NN=NN,CNN=CNN,n_epoch=10,n_batch=100,verbose=True)\n",
        "\n",
        "cnn1.fit(X_train[0:1000], y_train[0:1000])\n",
        "y_pred = cnn1.predict(X_valid[0:500])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZnIUwtwP35I",
        "outputId": "c7276978-0457-4634-c86e-7d462b9d1858"
      },
      "source": [
        "# Positive solution rate\n",
        "accuracy = accuracy_score(np.argmax(y_valid[0:500],axis=1), y_pred)\n",
        "print('accuracy:{:.3f}'.format(accuracy))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:0.894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "ffZHfZjwTGdp",
        "outputId": "eec51d36-f1d2-4b76-8821-ee5eef9d1ae8"
      },
      "source": [
        "# Visualize the loss function for each epoch\n",
        "plt.rcParams[\"font.size\"] = 20\n",
        "fig = plt.subplots(figsize=(16,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"LOSS\")\n",
        "plt.plot(cnn1.log_loss, 'bo--')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"ACC\")\n",
        "plt.plot(cnn1.log_acc, 'rs--')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fda1e9cfad0>]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}